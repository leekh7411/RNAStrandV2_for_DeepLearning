{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from utils import *\n",
    "from collections import defaultdict\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "\n",
    "# Easy RNASTRAND database preprocessor \n",
    "# for Machine Learning, Deep Learning\n",
    "class MLRNAStrandv2():\n",
    "    def __init__(self):\n",
    "        # static path\n",
    "        self.npz = \"preprocessed.npz\"\n",
    "        self.dp_path    = \"RNA_STRAND_v2_0_dp\"\n",
    "        self.dp_type    = \"dp\"\n",
    "        self.bpseq_path = \"RNA_STRAND_v2_0_bpseq\"\n",
    "        self.bpseq_type = \"bpseq\"\n",
    "        \n",
    "    def load(self):\n",
    "        dataset = np.load(self.npz)\n",
    "        X    = dataset[\"X\"] # X    : RNA sequence(onehot encoded)\n",
    "        L    = dataset[\"L\"] # L    : RNA sequence letter (not encoded)\n",
    "        C    = dataset[\"C\"] # C    : RNA sequence's secondary structure link info (dictionary)\n",
    "        A    = dataset[\"A\"] # A    : RNA sequence's secondary structure link adjacency matrix (scipy.sparse.coo_matrix)\n",
    "        N    = dataset[\"N\"] # N    : RNA sequence's length \n",
    "        S    = dataset[\"S\"] # S    : RNA sequence's secondary structure dot-bracket format (onehot encoded)\n",
    "        E    = dataset[\"E\"] # E    : RNA sequence's secondary structure dot-bracket base structure elements (onehot encoded)\n",
    "        ID   = dataset[\"ID\"] # ids\n",
    "        \n",
    "        print(\"Load dataset : {}\".format(self.npz))\n",
    "        print(\"X : {}\".format(X.shape))\n",
    "        print(\"L : {}\".format(L.shape))\n",
    "        print(\"C : {}\".format(C.shape))\n",
    "        print(\"A : {}\".format(A.shape))\n",
    "        print(\"N : {}\".format(N.shape))\n",
    "        print(\"S : {}\".format(S.shape))\n",
    "        print(\"E : {}\".format(E.shape))\n",
    "        print(\"ID : {}\".format(ID.shape))\n",
    "        \n",
    "        return X,L,C,A,N,S,E,ID\n",
    "                \n",
    "    def save(self):\n",
    "        self.dp_file_list    = getFileList(self.dp_path, ftype=self.dp_type)\n",
    "        self.bpseq_file_list = getFileList(self.bpseq_path, ftype=self.bpseq_type)\n",
    "        \n",
    "        # Table for RNA encoding\n",
    "        self.onehot_RNA = onehotTableRNA()\n",
    "        self.onehot_DOT = onehotTableDot()\n",
    "        self.data_saver()\n",
    "    \n",
    "    def data_saver(self):\n",
    "        # Get belows from bpseq file\n",
    "        # 1. data-ID (ids)\n",
    "        # 2. onehot-encoded sequence (X)\n",
    "        # 3. seqeunce character (S)\n",
    "        # 4. connection dictionary (C)\n",
    "        # 5. adjacency matrix(sparse matrix) (A)\n",
    "        # 6. sequence length (N)\n",
    "                \n",
    "        print(\"Start RNA dataset preprocessing...\")\n",
    "        self.ids = []\n",
    "        print(\">> Get all file's id\")\n",
    "        for bp_file in self.bpseq_file_list:\n",
    "            _id = bp_file.split(\"/\")[1]\n",
    "            _id = _id.split(\".\")[0]\n",
    "            self.ids.append(_id)\n",
    "        \n",
    "        for dp_file in self.dp_file_list:\n",
    "            _id = dp_file.split(\"/\")[1]\n",
    "            _id = _id.split(\".\")[0]\n",
    "            self.ids.append(_id)\n",
    "            \n",
    "        # eliminate redundant id\n",
    "        self.ids = list(set(self.ids))\n",
    "        print(\"number of ids : {}\".format(len(self.ids)))\n",
    "        X,L,C,A,N,S,E,ID = [],[],[],[],[],[],[],[]\n",
    "        \n",
    "        print(\">> preprocess bpseq, dp format files\")\n",
    "        for i, _id in enumerate(self.ids):\n",
    "            if i % 100 == 0:\n",
    "                print(\"processed {} / {}\".format(i, len(self.ids)))\n",
    "                \n",
    "            bp_file = self.bpseq_path + \"/\" + _id + \".\" + self.bpseq_type\n",
    "            dp_file = self.dp_path    + \"/\" + _id + \".\" + self.dp_type\n",
    "            \n",
    "            bp_ret  = self.bpseq_encoding(bp_file)\n",
    "            if len(bp_ret) == 2: \n",
    "                #print(\"error 1\")\n",
    "                continue \n",
    "            else: \n",
    "                (_, onehot_letters, letters, connections, adj, seq_length) = bp_ret\n",
    "            \n",
    "            dp_ret = self.dp_encoding(dp_file)\n",
    "            if len(dp_ret) == 0 :\n",
    "                #print(\"error 2\")\n",
    "                continue\n",
    "            else: \n",
    "                (_, dot , onehot_dot) = dp_ret\n",
    "            \n",
    "            dot_elements = dotbracket_to_elements(dot)\n",
    "            dot_elements = elements_structure_encoding(dot_elements)\n",
    "            \n",
    "            X.append(onehot_letters)\n",
    "            L.append(letters)\n",
    "            C.append(connections)\n",
    "            A.append(adj)\n",
    "            N.append(seq_length)\n",
    "            S.append(onehot_dot)\n",
    "            E.append(dot_elements)\n",
    "            ID.append(_id)\n",
    "        \n",
    "        \n",
    "        np.savez(self.npz, # npz file path\n",
    "                 X=np.array(X), # X : RNA sequence(onehot encoded)\n",
    "                 L=np.array(L), # L : RNA sequence letter (not encoded)\n",
    "                 C=np.array(C), # C : RNA sequence's secondary structure link info (dictionary)\n",
    "                 A=np.array(A), # A : RNA sequence's secondary structure link adjacency matrix (scipy.sparse.coo_matrix)\n",
    "                 N=np.array(N), # N : RNA sequence's length \n",
    "                 S=np.array(S), # S : RNA sequence's secondary structure dot-bracket format (onehot encoded)\n",
    "                 E=np.array(E), # E : RNA sequence's secondary structure dot-bracket base structure elements (onehot encoded)\n",
    "                 ID = np.array(ID)) # ids\n",
    "        \n",
    "        print(\"Completely saved -> {}\".format(self.npz))\n",
    "        \n",
    "    def bpseq_encoding(self, bpseq_file):\n",
    "        # Split file path to get ID of bpseq-file\n",
    "        data_id = bpseq_file.split(\"/\")[1]\n",
    "        data_id = data_id.split(\".\")[0]\n",
    "        \n",
    "        # Load file\n",
    "        f = open(bpseq_file,\"r\")\n",
    "        \n",
    "        # Check the file error \n",
    "        try:\n",
    "            f_lines = f.readlines()\n",
    "        except Exception as ex :\n",
    "            return [data_id, \"Data read error\"]\n",
    "        \n",
    "        # return dataset\n",
    "        onehot_letters = []\n",
    "        letters = []\n",
    "        rows = []\n",
    "        cols = []\n",
    "        data = []\n",
    "        connections = defaultdict(lambda: 0)\n",
    "        \n",
    "        for line in f_lines:\n",
    "            if line[0] not in set([\"#\",\" \"]):\n",
    "                idx, seq, link_idx = line.split()\n",
    "                idx = int(idx)\n",
    "                link_idx = int(link_idx)\n",
    "                seq = seq.upper()\n",
    "                \n",
    "                # Check the invalid bpseq file\n",
    "                if seq not in \"ACGU\":\n",
    "                    return [data_id,\"Not ACGU format\"]\n",
    "                \n",
    "                letters.append(seq)\n",
    "                onehot_letters.append(self.onehot_RNA[seq])\n",
    "                \n",
    "                connections[idx] = link_idx\n",
    "                \n",
    "                if link_idx > 0:\n",
    "                    rows.append(idx-1)\n",
    "                    cols.append(link_idx-1)\n",
    "                    data.append(1)\n",
    "                \n",
    "        # convert defaultdict to dict(for save as npz type)\n",
    "        connections = dict(connections)\n",
    "        \n",
    "        # make adjacency matrix\n",
    "        N           = len(letters)\n",
    "        rows        = np.array(rows)\n",
    "        cols        = np.array(cols)\n",
    "        adj         = sp.coo_matrix((data,(rows, cols)),shape=(N,N))\n",
    "        \n",
    "        return (data_id, onehot_letters, letters, connections, adj, N)\n",
    "        \n",
    "   \n",
    "    def dp_encoding(self, dp_file):\n",
    "        # Split file path to get ID of bpseq-file\n",
    "        data_id = dp_file.split(\"/\")[1]\n",
    "        data_id = data_id.split(\".\")[0]\n",
    "        \n",
    "        f = open(dp_file,\"r\")\n",
    "        \n",
    "        try:\n",
    "            f_lines = f.readlines()\n",
    "        except Exception as ex :\n",
    "            return []\n",
    "                \n",
    "        lines = \"\"\n",
    "        for line in f_lines:\n",
    "            if line[0] not in set([\"#\",\" \"]):\n",
    "                lines += line\n",
    "        \n",
    "        split_lines = lines.split()\n",
    "        seq_list = split_lines[:len(split_lines)//2]\n",
    "        dot_list = split_lines[len(split_lines)//2:]\n",
    "        \n",
    "        dot = \"\"\n",
    "        onehot_dot = []\n",
    "        for d in dot_list:\n",
    "            dot += d\n",
    "            onehot_dot.append(self.onehot_DOT[d])\n",
    "        \n",
    "        onehot_dot = np.array(onehot_dot)\n",
    "        \n",
    "        return (data_id, dot, onehot_dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MLRNAStrandv2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load dataset : preprocessed.npz\n",
      "X : (3235,)\n",
      "L : (3235,)\n",
      "C : (3235,)\n",
      "A : (3235,)\n",
      "N : (3235,)\n",
      "S : (3235,)\n",
      "E : (3235,)\n",
      "ID : (3235,)\n"
     ]
    }
   ],
   "source": [
    "X,L,C,A,N,S,E,ID = dataset.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X : (3235,)\n",
      "L : (3235,)\n",
      "C : (3235,)\n",
      "A : (3235,)\n",
      "N : (3235,)\n",
      "S : (3235,)\n",
      "E : (3235,)\n",
      "ID : (3235,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X : {}\".format(X.shape))\n",
    "print(\"L : {}\".format(L.shape))\n",
    "print(\"C : {}\".format(C.shape))\n",
    "print(\"A : {}\".format(A.shape))\n",
    "print(\"N : {}\".format(N.shape))\n",
    "print(\"S : {}\".format(S.shape))\n",
    "print(\"E : {}\".format(E.shape))\n",
    "print(\"ID : {}\".format(ID.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
